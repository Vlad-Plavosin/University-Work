{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8210b19",
   "metadata": {},
   "source": [
    "## A.I. Assignment 5\n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "By the end of this lab, you should be able to:\n",
    "* Get more familiar with tensors in pytorch \n",
    "* Create a simple multilayer perceptron model with pytorch\n",
    "* Visualise the parameters\n",
    "\n",
    "\n",
    "### Task\n",
    "\n",
    "Build a fully connected feed forward network that adds two bits. Determine the a propper achitecture for this network (what database you use for this problem? how many layers? how many neurons on each layer? what is the activation function? what is the loss function? etc)\n",
    "\n",
    "Create at least 3 such networks and compare their performance (how accurate they are?, how farst they are trained to get at 1 accuracy?)\n",
    "\n",
    "Display for the best one the weights for each layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3614e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5ee7e7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "model1 = nn.Sequential(OrderedDict([\n",
    "    ('hidden', nn.Linear(2, 4)),\n",
    "    ('activation', nn.Sigmoid()),\n",
    "    ('output', nn.Linear(4, 1)),\n",
    "    ('sigmoid', nn.Sigmoid())\n",
    "]))\n",
    "\n",
    "model2 = nn.Sequential(OrderedDict([\n",
    "    ('hidden1', nn.Linear(2, 8)),\n",
    "    ('tanh1', nn.Tanh()),\n",
    "    ('hidden2', nn.Linear(8, 8)),\n",
    "    ('relu2', nn.ReLU()),\n",
    "    ('output', nn.Linear(8, 1)),\n",
    "    ('sigmoid', nn.Sigmoid())\n",
    "]))\n",
    "\n",
    "model3 = nn.Sequential(OrderedDict([\n",
    "    ('hidden1', nn.Linear(2, 8)),\n",
    "    ('relu1', nn.ReLU()),\n",
    "    ('hidden2', nn.Linear(8, 8)),\n",
    "    ('relu2', nn.ReLU()),\n",
    "    ('output', nn.Linear(8, 1)),\n",
    "    ('sigmoid', nn.Sigmoid())\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "665ae958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (hidden): Linear(in_features=2, out_features=4, bias=True)\n",
      "  (activation): Sigmoid()\n",
      "  (output): Linear(in_features=4, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Sequential(\n",
      "  (hidden1): Linear(in_features=2, out_features=8, bias=True)\n",
      "  (tanh1): Tanh()\n",
      "  (hidden2): Linear(in_features=8, out_features=8, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (output): Linear(in_features=8, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Sequential(\n",
      "  (hidden1): Linear(in_features=2, out_features=8, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (hidden2): Linear(in_features=8, out_features=8, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (output): Linear(in_features=8, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model1)\n",
    "print(model2)\n",
    "print(model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e26f0d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "data_in = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
    "print(data_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4fb16bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]])\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "data_target = torch.tensor([[0], [0], [0], [1]], dtype=torch.float32)\n",
    "print(data_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "69d920ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "import torch.optim as optim\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer1 = optim.Adam(model1.parameters(), lr=0.1)\n",
    "optimizer2 = optim.Adam(model2.parameters(), lr=0.1)\n",
    "optimizer3 = optim.Adam(model3.parameters(), lr=0.1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cde91f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st model:\n",
      "Epoch [100/1000], Loss: 0.0000\n",
      "Epoch [200/1000], Loss: 0.0000\n",
      "Epoch [300/1000], Loss: 0.0000\n",
      "Epoch [400/1000], Loss: 0.0000\n",
      "Epoch [500/1000], Loss: 0.0000\n",
      "Epoch [600/1000], Loss: 0.0000\n",
      "Epoch [700/1000], Loss: 0.0000\n",
      "Epoch [800/1000], Loss: 0.0000\n",
      "Epoch [900/1000], Loss: 0.0000\n",
      "Epoch [1000/1000], Loss: 0.0000\n",
      "\n",
      "2nd model:\n",
      "Epoch [100/1000], Loss: 0.2500\n",
      "Epoch [200/1000], Loss: 0.2500\n",
      "Epoch [300/1000], Loss: 0.2500\n",
      "Epoch [400/1000], Loss: 0.2500\n",
      "Epoch [500/1000], Loss: 0.2500\n",
      "Epoch [600/1000], Loss: 0.2500\n",
      "Epoch [700/1000], Loss: 0.2500\n",
      "Epoch [800/1000], Loss: 0.2500\n",
      "Epoch [900/1000], Loss: 0.2500\n",
      "Epoch [1000/1000], Loss: 0.2500\n",
      "\n",
      "3rd model:\n",
      "Epoch [100/1000], Loss: 0.0000\n",
      "Epoch [200/1000], Loss: 0.0000\n",
      "Epoch [300/1000], Loss: 0.0000\n",
      "Epoch [400/1000], Loss: 0.0000\n",
      "Epoch [500/1000], Loss: 0.0000\n",
      "Epoch [600/1000], Loss: 0.0000\n",
      "Epoch [700/1000], Loss: 0.0000\n",
      "Epoch [800/1000], Loss: 0.0000\n",
      "Epoch [900/1000], Loss: 0.0000\n",
      "Epoch [1000/1000], Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "num_epochs = 1000\n",
    "\n",
    "print(\"1st model:\")\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    outputs_pred = model1(data_in)\n",
    "    loss = criterion(outputs_pred, data_target)\n",
    "    \n",
    "    optimizer1.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer1.step()\n",
    "    \n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "print(\"\\n2nd model:\")\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs_pred = model2(data_in)\n",
    "    loss = criterion(outputs_pred, data_target)\n",
    "    \n",
    "    optimizer2.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer2.step()\n",
    "\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "print(\"\\n3rd model:\")\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    outputs_pred = model3(data_in)\n",
    "    loss = criterion(outputs_pred, data_target)\n",
    "    \n",
    "    optimizer3.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer3.step()\n",
    "    \n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "dff3ec1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st model training accuracy: 1.0000\n",
      "2nd model training accuracy: 1.0000\n",
      "3rd model training accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model1(data_in)\n",
    "    predicted = (outputs >= 0.5).float()\n",
    "    accuracy = (predicted == data_target).float().mean()\n",
    "    print(f'1st model training accuracy: {accuracy.item():.4f}')\n",
    "    \n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model2(data_in)\n",
    "    predicted = (outputs >= 0.5).float()\n",
    "    accuracy = (predicted == data_target).float().mean()\n",
    "    print(f'2nd model training accuracy: {accuracy.item():.4f}')\n",
    "    \n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model3(data_in)\n",
    "    predicted = (outputs >= 0.5).float()\n",
    "    accuracy = (predicted == data_target).float().mean()\n",
    "    print(f'3rd model training accuracy: {accuracy.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c1a7518b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st model:\n",
      "hidden.weight tensor([[ 5.8960, -7.7423],\n",
      "        [-6.7464, -8.0481],\n",
      "        [10.0597, -7.4903],\n",
      "        [ 3.7486, -7.0765]])\n",
      "hidden.bias tensor([-3.0219,  2.0471,  2.5691, -1.3022])\n",
      "output.weight tensor([[ 5.7776, -3.8476, -9.1566,  4.9888]])\n",
      "output.bias tensor([4.4876])\n",
      "\n",
      "2nd model:\n",
      "hidden1.weight tensor([[ 0.0737,  0.4225],\n",
      "        [ 0.3748,  1.6445],\n",
      "        [ 2.6994,  2.7623],\n",
      "        [-0.5931, -0.2934],\n",
      "        [ 0.8712,  1.3586],\n",
      "        [ 2.5788,  2.3947],\n",
      "        [ 0.9098,  0.5764],\n",
      "        [-1.8320,  0.0990]])\n",
      "hidden1.bias tensor([ 0.4425, -1.1718, -0.6324,  0.5992, -1.6879, -0.7530, -0.8112, -0.1455])\n",
      "hidden2.weight tensor([[-0.1480, -1.1052,  1.4911,  0.0338, -1.8264,  1.0484, -0.4551, -0.0603],\n",
      "        [ 0.9302, -1.6230, -1.2788, -0.1508, -2.0375, -1.6527, -0.6732,  0.3150],\n",
      "        [ 0.1274, -0.3537,  1.2566,  0.0374, -1.6002,  0.8401, -0.7418,  1.4282],\n",
      "        [-0.1043,  2.5768,  0.1658, -0.4396,  2.5794,  0.6820,  1.0801, -0.6336],\n",
      "        [-0.8589,  0.6991,  0.2649, -0.1814,  0.4123,  0.2610,  0.6148,  0.6382],\n",
      "        [-0.6255,  0.3573, -0.3645,  0.9532,  0.5198,  0.2946, -0.7173, -0.4674],\n",
      "        [-0.2414, -0.3445, -0.1214, -0.3504,  0.1962,  0.2917, -0.3288, -0.1659],\n",
      "        [ 0.1829, -1.6373,  1.4465,  0.2579, -1.8638,  1.2029, -0.6979,  0.2874]])\n",
      "hidden2.bias tensor([ 0.3132,  1.2473,  0.6128, -0.4845, -0.5560, -0.4286, -0.2834,  0.1839])\n",
      "output.weight tensor([[ 0.9650, -2.2017,  1.5701, -1.9397, -0.3292, -0.5331,  0.1159,  1.3872]])\n",
      "output.bias tensor([-0.2111])\n",
      "\n",
      "3rd model:\n",
      "hidden1.weight tensor([[ 0.2191, -1.5133],\n",
      "        [-0.2759,  0.2794],\n",
      "        [ 2.3408,  2.6888],\n",
      "        [-1.3133,  1.4536],\n",
      "        [ 2.1124, -2.0093],\n",
      "        [ 1.3442,  0.8657],\n",
      "        [-1.0605, -0.5817],\n",
      "        [-0.1777, -0.6550]])\n",
      "hidden1.bias tensor([ 1.0798, -0.4123,  0.0393, -0.2871, -0.0766, -1.1934,  1.6200, -0.2666])\n",
      "hidden2.weight tensor([[-0.8248, -0.1702,  0.4236, -0.4273, -0.3675,  1.0325, -0.7530,  0.3095],\n",
      "        [-0.5461, -0.1506, -0.7491,  0.0210, -0.4418, -0.3745, -0.6886,  0.0793],\n",
      "        [-0.6281,  0.1652,  0.8767, -0.9842, -0.8787,  1.8461, -0.6116, -0.1419],\n",
      "        [-1.2651, -0.2323,  2.1258,  0.5773,  2.2408,  0.4164, -1.0125,  0.0378],\n",
      "        [-0.3920, -0.1473, -0.4380, -0.1824, -0.6131,  0.6884, -0.6779,  0.2470],\n",
      "        [-0.5145,  0.1502,  0.7856, -1.0864, -0.7577,  1.7974, -1.3088, -0.2299],\n",
      "        [-1.2723,  0.0593,  1.0138, -1.1034, -0.7269,  1.8433, -1.0861, -0.3460],\n",
      "        [-0.9358, -0.3034,  0.9029, -1.0767, -0.8816,  1.9237, -1.4242,  0.1085]])\n",
      "hidden2.bias tensor([-0.8648, -0.6525, -0.6087, -0.0470, -0.4819, -0.7840, -0.3535, -0.5360])\n",
      "output.weight tensor([[-1.3474,  0.3614, -1.5506,  2.2524,  0.1672, -1.5612, -1.4369, -1.3819]])\n",
      "output.bias tensor([-4.6471])\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "print(\"1st model:\")\n",
    "for name, param in model1.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)\n",
    "        \n",
    "print(\"\\n2nd model:\")\n",
    "for name, param in model2.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)\n",
    "        \n",
    "print(\"\\n3rd model:\")\n",
    "for name, param in model3.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdf09ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bea66c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29c65a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiclasses",
   "language": "python",
   "name": "aiclasses"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
